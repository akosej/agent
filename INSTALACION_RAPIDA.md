# ğŸš€ InstalaciÃ³n RÃ¡pida - AgentIA Open Source

Esta guÃ­a te llevarÃ¡ de 0 a tener el agente funcionando en menos de 10 minutos.

## Paso 1: Instalar Ollama (3 minutos)

### Windows
1. Ve a https://ollama.com/download/windows
2. Descarga e instala el ejecutable
3. Abre PowerShell y ejecuta:
```powershell
ollama pull llama3.2:3b
```

### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b
```

### macOS
```bash
brew install ollama
ollama pull llama3.2:3b
```

â±ï¸ **Tiempo**: ~3 minutos (descarga de ~2GB)

## Paso 2: Instalar el Agente (2 minutos)

```powershell
# Clonar el repositorio
git clone https://github.com/yourusername/agent
cd agent

# Instalar dependencias
go mod download

# Compilar
go build -o agent.exe ./cmd/agent
```

## Paso 3: Configurar (1 minuto)

Edita `configs/config.yaml` (opcional, la configuraciÃ³n por defecto funciona):

```yaml
nlp:
  model: "llama3.2:3b"
  ollama_url: "http://localhost:11434"
```

## Paso 4: Â¡Ejecutar! (5 segundos)

```powershell
# AsegÃºrate de que Ollama estÃ¡ corriendo
ollama serve

# En otra terminal, ejecuta el agente
.\agent.exe
```

## âœ… Â¡Listo!

Ahora puedes chatear con tu agente:

```
> Hola, Â¿cÃ³mo estÃ¡s?
AgentIA: Â¡Hola! Estoy muy bien...

> Â¿CuÃ¡l es la capital de EspaÃ±a?
AgentIA: La capital de EspaÃ±a es Madrid...
```

## ğŸ”§ Comandos Ãštiles

- `/help` - Ver ayuda
- `/stats` - Ver estadÃ­sticas
- `/export` - Exportar conocimiento aprendido
- `/exit` - Salir

## ğŸ¯ PrÃ³ximos Pasos (Opcional)

### Usar un modelo mÃ¡s rÃ¡pido (si va lento):
```powershell
ollama pull llama3.2:1b
# Actualiza model en config.yaml a "llama3.2:1b"
```

### Usar un modelo de mejor calidad:
```powershell
ollama pull mistral:7b
# Actualiza model en config.yaml a "mistral:7b"
```

### Agregar reconocimiento de voz:
Ve a la secciÃ³n "InstalaciÃ³n de Whisper.cpp" en el README.md

## â“ Problemas Comunes

**Error: "connection refused"**
```powershell
# Inicia Ollama
ollama serve
```

**Error: "modelo no encontrado"**
```powershell
# Descarga el modelo
ollama pull llama3.2:3b
```

**El agente va lento**
```powershell
# Usa un modelo mÃ¡s pequeÃ±o
ollama pull llama3.2:1b
```

## ğŸ“š MÃ¡s InformaciÃ³n

- [README completo](README.md)
- [Arquitectura del proyecto](ARCHITECTURE.md)
- [Ejemplos de uso](EXAMPLES.md)

---

**Â¡Disfruta de tu agente IA completamente privado y offline!** ğŸ‰
