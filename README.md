# AgentIA - Agente Inteligente con Aprendizaje y Reconocimiento de Voz

Un agente conversacional inteligente desarrollado en Go que aprende de las interacciones y cuenta con capacidades de reconocimiento de voz. **100% Open Source y funciona completamente offline** - no necesitas API keys ni conexi√≥n a internet.

## üöÄ Caracter√≠sticas

- **Procesamiento de Lenguaje Natural (NLP)**: Usa **Ollama** para ejecutar modelos como Llama, Mistral, Phi3 localmente
- **Reconocimiento de Voz**: Transcribe audio usando **Whisper.cpp** (ejecutado localmente)
- **Sistema de Aprendizaje**: Mejora continuamente con cada interacci√≥n
- **Detecci√≥n de Intenciones**: Identifica qu√© quiere hacer el usuario
- **Almacenamiento Persistente**: Guarda conversaciones y patrones en SQLite
- **Estad√≠sticas**: Rastrea m√©tricas de rendimiento y feedback
- **Exportaci√≥n de Conocimiento**: Permite guardar y cargar el conocimiento aprendido
- **üîí 100% Privado**: Todos los datos y procesamiento permanecen en tu m√°quina
- **üåê Funciona Offline**: No requiere conexi√≥n a internet despu√©s de la instalaci√≥n

## üìã Requisitos Previos

- Go 1.21 o superior
- **Ollama** (para el modelo de lenguaje local)
- **Whisper.cpp** (opcional, solo para reconocimiento de voz)
- PortAudio (opcional, solo para captura de audio en vivo)

### Instalaci√≥n de Ollama (REQUERIDO)

Ollama permite ejecutar modelos de IA localmente sin necesidad de API keys.

**Windows:**
1. Descarga el instalador desde: https://ollama.com/download/windows
2. Ejecuta el instalador
3. Abre PowerShell y descarga un modelo:
```powershell
ollama pull llama3.2:3b
```

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b
```

**macOS:**
```bash
brew install ollama
ollama pull llama3.2:3b
```

**Modelos recomendados:**
- `llama3.2:1b` - Ultrarr√°pido (1GB RAM) - ideal para equipos limitados
- `llama3.2:3b` - Balanceado (3GB RAM) - **RECOMENDADO**
- `mistral:7b` - Alta calidad (4GB RAM)
- `phi3:mini` - Eficiente (2GB RAM)
- `qwen2.5:3b` - Multiling√ºe (3GB RAM)

### Instalaci√≥n de Whisper.cpp (OPCIONAL - solo para voz)

Solo necesario si quieres usar reconocimiento de voz.

**Windows:**
```powershell
# Clonar whisper.cpp
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp

# Compilar (necesitas Visual Studio o MinGW)
cmake -B build
cmake --build build --config Release

# Descargar modelo (base es suficiente para espa√±ol)
cd models
.\download-ggml-model.ps1 base
cd ..\..
```

**Linux/macOS:**
```bash
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make
bash ./models/download-ggml-model.sh base
cd ..
```

### Instalaci√≥n de PortAudio (OPCIONAL - solo para captura de voz en vivo)

**Windows:**
```powershell
pacman -S mingw-w64-x86_64-portaudio  # Con MSYS2
```

**Linux:**
```bash
sudo apt-get install portaudio19-dev
```

**macOS:**
```bash
brew install portaudio
```

## üõ†Ô∏è Instalaci√≥n del Agente

1. **Clonar el repositorio:**
```powershell
git clone https://github.com/yourusername/agent
cd agent
```

2. **Instalar dependencias Go:**
```powershell
go mod download
```

3. **Configurar rutas en config.yaml:**

Edita `configs/config.yaml` y ajusta las rutas seg√∫n tu instalaci√≥n:

```yaml
nlp:
  model: "llama3.2:3b"  # El modelo que descargaste con Ollama
  ollama_url: "http://localhost:11434"  # URL por defecto de Ollama

speech:
  provider: "whisper-cpp"  # o "whisper-api" si usas un servidor
  whisper_path: "./whisper.cpp/main"  # Ruta a tu instalaci√≥n de whisper.cpp
  model_path: "./whisper.cpp/models/ggml-base.bin"
```

4. **Compilar el proyecto:**
```powershell
go build -o agent.exe ./cmd/agent
```

5. **Iniciar Ollama (si no est√° corriendo):**
```powershell
ollama serve
```

## üéØ Uso

### Modo Texto (Recomendado para empezar)

Ejecutar el agente en modo texto:
```powershell
.\agent.exe
```

Luego simplemente escribe tus mensajes:
```
> Hola, ¬øc√≥mo est√°s?
AgentIA: ¬°Hola! Estoy muy bien, gracias por preguntar. ¬øEn qu√© puedo ayudarte hoy?

> ¬øCu√°l es la capital de Francia?
AgentIA: La capital de Francia es Par√≠s...
```

### Comandos Disponibles

Dentro del agente, puedes usar estos comandos:

- `/help` o `/ayuda` - Muestra la ayuda
- `/stats` - Muestra estad√≠sticas del agente
- `/export` - Exporta el conocimiento aprendido a un archivo JSON
- `/exit`, `/salir` o `/quit` - Cierra el agente

### Modo Voz

Para habilitar el reconocimiento de voz, editar `cmd/agent/main.go`:
```go
EnableSpeech: true,  // Cambiar de false a true
```

Luego recompilar:
```powershell
go build -o agent.exe ./cmd/agent
```

## üìÅ Estructura del Proyecto

```
agent/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ agent/
‚îÇ       ‚îî‚îÄ‚îÄ main.go              # Punto de entrada principal
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.go             # Coordinador principal
‚îÇ   ‚îú‚îÄ‚îÄ speech/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recognizer.go        # Captura de audio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transcriber.go       # Transcripci√≥n a texto
‚îÇ   ‚îú‚îÄ‚îÄ nlp/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processor.go         # Procesamiento NLP
‚îÇ   ‚îî‚îÄ‚îÄ learning/
‚îÇ       ‚îî‚îÄ‚îÄ engine.go            # Motor de aprendizaje
‚îú‚îÄ‚îÄ pkg/
‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ storage.go           # Almacenamiento SQLite
‚îÇ   ‚îî‚îÄ‚îÄ logger/
‚îÇ       ‚îî‚îÄ‚îÄ logger.go            # Sistema de logging
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml              # Configuraci√≥n principal
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ agent.db                 # Base de datos (se crea autom√°ticamente)
‚îÇ   ‚îî‚îÄ‚îÄ conversations/           # Conversaciones guardadas
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ agent.log                # Logs de la aplicaci√≥n
‚îú‚îÄ‚îÄ .env                         # Variables de entorno (crear desde .env.example)
‚îú‚îÄ‚îÄ .env.example                 # Plantilla de variables de entorno
‚îú‚îÄ‚îÄ go.mod                       # Dependencias de Go
‚îî‚îÄ‚îÄ README.md                    # Este archivo
```

## ‚öôÔ∏è Configuraci√≥n

Editar `configs/config.yaml` para personalizar el comportamiento:

```yaml
agent:
  name: "AgentIA"
  version: "2.0.0"
  language: "es"

nlp:
  model: "llama3.2:3b"  # Cualquier modelo de Ollama
  max_tokens: 500
  temperature: 0.7
  ollama_url: "http://localhost:11434"

speech:
  provider: "whisper-cpp"
  whisper_path: "./whisper.cpp/main"
  model_path: "./whisper.cpp/models/ggml-base.bin"

learning:
  enabled: true
  learning_rate: 0.01
  confidence_threshold: 0.7
```

### Cambiar Modelo de IA

Para usar un modelo diferente:
```powershell
# Descargar otro modelo
ollama pull mistral:7b

# Actualizar config.yaml
# nlp:
#   model: "mistral:7b"
```

## üß† Sistema de Aprendizaje

El agente aprende de las interacciones de las siguientes formas:

1. **Patrones de Conversaci√≥n**: Identifica intenciones comunes y respuestas exitosas
2. **Contexto**: Mantiene el historial de la conversaci√≥n
3. **Feedback**: Mejora bas√°ndose en la retroalimentaci√≥n (por implementar en UI)
4. **Estad√≠sticas**: Rastrea m√©tricas para mejorar continuamente

### Exportar e Importar Conocimiento

```
> /export
Conocimiento exportado a: data/knowledge_export_1234567890.json
```

Para importar conocimiento previo, agregar funci√≥n en el c√≥digo.

## üîß Desarrollo

### Ejecutar en modo desarrollo:
```powershell
go run ./cmd/agent
```

### Ejecutar tests:
```powershell
go test ./...
```

### Verificar c√≥digo:
```powershell
go vet ./...
```

### Formatear c√≥digo:
```powershell
go fmt ./...
```

## üìä Logs y Depuraci√≥n

Los logs se guardan en `logs/agent.log`. Para cambiar el nivel de logging, editar `configs/config.yaml`:

```yaml
logging:
  level: "debug"  # debug, info, warn, error
```

## üêõ Soluci√≥n de Problemas

### Error: "error llamando a Ollama" o "connection refused"
**Causa**: Ollama no est√° corriendo
**Soluci√≥n**: 
```powershell
ollama serve
```
O reinicia el servicio de Ollama en Windows.

### Error: "modelo no encontrado"
**Causa**: No has descargado el modelo especificado en config.yaml
**Soluci√≥n**:
```powershell
ollama pull llama3.2:3b  # O el modelo que especifiques
```

### Error con Whisper.cpp: "whisperPath no configurado"
**Causa**: No has configurado la ruta a whisper.cpp en config.yaml
**Soluci√≥n**: 
1. Instala whisper.cpp (ver secci√≥n de instalaci√≥n)
2. Actualiza `whisper_path` en config.yaml con la ruta correcta

### El agente responde muy lento
**Soluci√≥n**: Usa un modelo m√°s peque√±o
```powershell
ollama pull llama3.2:1b  # M√°s r√°pido
# Actualiza config.yaml: model: "llama3.2:1b"
```

### Error de compilaci√≥n con PortAudio
- Solo necesario para captura de voz en vivo (opcional)
- Verifica que PortAudio est√© instalado correctamente
- En Windows, asegura que MSYS2 est√© en el PATH

### Base de datos bloqueada
- Cierra todas las instancias del agente antes de iniciar una nueva

## üéØ Ventajas de Esta Versi√≥n Open Source

‚úÖ **Sin costos de API**: No pagas por cada consulta  
‚úÖ **100% Privado**: Tus conversaciones nunca salen de tu PC  
‚úÖ **Funciona offline**: No necesitas internet despu√©s de instalar  
‚úÖ **Personalizable**: Cambia modelos seg√∫n tus necesidades  
‚úÖ **R√°pido**: Respuestas instant√°neas en hardware moderno  
‚úÖ **Sin l√≠mites**: Usa el agente tanto como quieras  

## üöß Roadmap

- [x] Migraci√≥n a Ollama (modelos locales)
- [x] Integraci√≥n con Whisper.cpp local
- [ ] Interface web con React
- [ ] Soporte para m√∫ltiples modelos simult√°neos
- [ ] API REST para integraci√≥n externa
- [ ] Sistema de plugins
- [ ] Memoria vectorial con embeddings locales
- [ ] Soporte para RAG (Retrieval Augmented Generation)

## üìù Licencia

MIT License - ver el archivo LICENSE para m√°s detalles

## ü§ù Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## üìß Contacto

Para preguntas o sugerencias, abrir un issue en el repositorio.

---

Desarrollado con ‚ù§Ô∏è usando Go
