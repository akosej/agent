# üîÑ Migraci√≥n a Open Source - AgentIA v2.0

## Resumen de Cambios

Este proyecto ha sido migrado de usar servicios pagos de OpenAI a soluciones **100% open source** que funcionan completamente en local.

## ‚ú® Principales Cambios

### 1. Procesamiento de Lenguaje Natural (NLP)
- **ANTES**: OpenAI GPT-3.5/4 (requiere API key y conexi√≥n a internet)
- **AHORA**: Ollama con modelos locales (Llama, Mistral, Phi3, etc.)
- **Archivo modificado**: `internal/nlp/processor.go`

### 2. Transcripci√≥n de Voz
- **ANTES**: OpenAI Whisper API (servicio en la nube)
- **AHORA**: Whisper.cpp (ejecutable local)
- **Archivo modificado**: `internal/speech/transcriber.go`

### 3. Configuraci√≥n
- **ANTES**: Requer√≠a `OPENAI_API_KEY` en `.env`
- **AHORA**: Solo necesita URLs locales de servicios
- **Archivos modificados**: 
  - `configs/config.yaml`
  - `cmd/agent/main.go`
  - `internal/agent/agent.go`

### 4. Dependencias
- **ANTES**: `github.com/sashabaranov/go-openai`
- **AHORA**: Cliente HTTP est√°ndar de Go
- **Archivo modificado**: `go.mod`

## üéØ Ventajas de la Migraci√≥n

| Aspecto | Antes | Ahora |
|---------|-------|-------|
| **Costo** | ~$0.002 por request | $0 (gratis) |
| **Privacidad** | Datos enviados a OpenAI | 100% local |
| **Internet** | Requerido | No necesario |
| **L√≠mites** | Rate limits de API | Ilimitado |
| **Velocidad** | Depende de internet | Inmediato en local |
| **Personalizaci√≥n** | Limitada | Total control |

## üì¶ Nuevos Requisitos

### Software Necesario

1. **Ollama** (requerido para NLP)
   - Descarga: https://ollama.com/
   - Modelos recomendados:
     - `llama3.2:1b` - Ultrarr√°pido (1GB)
     - `llama3.2:3b` - Balanceado (3GB) ‚≠ê
     - `mistral:7b` - Alta calidad (4GB)

2. **Whisper.cpp** (opcional, solo para voz)
   - Repositorio: https://github.com/ggerganov/whisper.cpp
   - Modelo recomendado: `ggml-base.bin`

### Hardware M√≠nimo

- **RAM**: 4GB (8GB recomendado)
- **Disco**: 5GB libres (para modelos)
- **CPU**: Cualquier CPU de 64 bits
- **GPU**: Opcional (acelera significativamente)

## üîß Cambios T√©cnicos Detallados

### 1. internal/nlp/processor.go

#### Estructuras Nuevas:
```go
type Message struct {
    Role    string `json:"role"`
    Content string `json:"content"`
}

type OllamaRequest struct {
    Model    string    `json:"model"`
    Messages []Message `json:"messages"`
    Stream   bool      `json:"stream"`
    Options  Options   `json:"options,omitempty"`
}
```

#### M√©todo Principal:
```go
func (p *Processor) callOllama(ctx context.Context, messages []Message) (string, error)
```

### 2. internal/speech/transcriber.go

#### M√©todos Nuevos:
```go
func NewTranscriber(whisperPath, modelPath, language string) *Transcriber
func NewTranscriberWithAPI(apiURL, language string) *Transcriber
func (t *Transcriber) transcribeWithWhisperCpp(ctx context.Context, audioPath string) (string, error)
```

### 3. configs/config.yaml

#### Nuevos Campos:
```yaml
nlp:
  ollama_url: "http://localhost:11434"
  
speech:
  whisper_path: "./whisper.cpp/main"
  model_path: "./models/ggml-base.bin"
  api_url: "http://localhost:8000"
```

### 4. internal/agent/agent.go

#### Config Actualizado:
```go
type Config struct {
    OllamaURL     string  // Nuevo
    WhisperPath   string  // Nuevo
    WhisperModel  string  // Nuevo
    WhisperAPIURL string  // Nuevo
    // OpenAIKey removido
    // DeepgramKey removido
}
```

## üöÄ Pasos para Migrar una Instalaci√≥n Existente

### 1. Instalar Ollama
```powershell
# Windows: Descargar desde ollama.com
# Luego:
ollama pull llama3.2:3b
```

### 2. Actualizar el C√≥digo
```powershell
git pull origin main
go mod download
go build -o agent.exe ./cmd/agent
```

### 3. Actualizar Configuraci√≥n
Edita `configs/config.yaml`:
```yaml
nlp:
  model: "llama3.2:3b"
  ollama_url: "http://localhost:11434"
```

### 4. Iniciar Ollama
```powershell
ollama serve
```

### 5. Ejecutar el Agente
```powershell
.\agent.exe
```

## üîç Comparaci√≥n de Funcionalidad

| Funci√≥n | Antes | Ahora | Status |
|---------|-------|-------|--------|
| Chat conversacional | ‚úÖ GPT-3.5 | ‚úÖ Llama/Mistral | ‚úÖ Mantenido |
| Detecci√≥n de intenciones | ‚úÖ GPT | ‚úÖ Modelo local | ‚úÖ Mantenido |
| Historial de conversaci√≥n | ‚úÖ | ‚úÖ | ‚úÖ Mantenido |
| Sistema de aprendizaje | ‚úÖ | ‚úÖ | ‚úÖ Mantenido |
| Transcripci√≥n de voz | ‚úÖ Whisper API | ‚úÖ Whisper.cpp | ‚úÖ Mantenido |
| Almacenamiento SQLite | ‚úÖ | ‚úÖ | ‚úÖ Mantenido |
| Estad√≠sticas | ‚úÖ | ‚úÖ | ‚úÖ Mantenido |
| Exportar conocimiento | ‚úÖ | ‚úÖ | ‚úÖ Mantenido |

## üìä Rendimiento Esperado

### Tiempos de Respuesta (en hardware moderno)

| Modelo | Primera respuesta | Respuestas siguientes | RAM |
|--------|-------------------|----------------------|-----|
| llama3.2:1b | ~2s | ~0.5s | 1GB |
| llama3.2:3b | ~3s | ~1s | 3GB |
| mistral:7b | ~5s | ~2s | 4GB |

### Calidad de Respuestas

- **llama3.2:1b**: Adecuado para conversaciones simples
- **llama3.2:3b**: Excelente para uso general ‚≠ê
- **mistral:7b**: Respuestas de alta calidad

## ‚ö†Ô∏è Limitaciones Conocidas

1. **Primera ejecuci√≥n lenta**: El modelo se carga en memoria (una sola vez)
2. **Modelos grandes requieren RAM**: Verifica requisitos antes de descargar
3. **Sin GPU**: Las respuestas ser√°n m√°s lentas (pero funcionales)

## üÜò Soporte

Si tienes problemas con la migraci√≥n:

1. Lee `INSTALACION_RAPIDA.md`
2. Revisa la secci√≥n "Soluci√≥n de Problemas" en `README.md`
3. Verifica que Ollama est√© corriendo: `ollama serve`
4. Confirma que el modelo est√© descargado: `ollama list`

## üìù Notas para Desarrolladores

### Testing con Diferentes Modelos

```powershell
# Descargar modelo
ollama pull phi3:mini

# Actualizar config.yaml
# nlp:
#   model: "phi3:mini"

# Reiniciar el agente
```

### Modo Debug

Edita `configs/config.yaml`:
```yaml
logging:
  level: "debug"
```

### Monitorear Ollama

```powershell
# Ver logs de Ollama
ollama logs

# Ver modelos instalados
ollama list

# Ver uso de recursos
ollama ps
```

## üéâ Conclusi√≥n

La migraci√≥n a open source hace que AgentIA sea:
- **M√°s accesible**: Sin costos de API
- **M√°s privado**: Datos nunca salen de tu PC
- **M√°s flexible**: Cambia modelos seg√∫n necesites
- **M√°s confiable**: No depende de servicios externos

¬°Disfruta de tu agente IA completamente aut√≥nomo! üöÄ
